# Robot navigation algorithms

A collection of algorithms for control and navigation of mobile robots. These programs were developed during my masters program's EMOR course tutorials (2016-17 session) at Warsaw University of Technology, Poland.

## Requirements
- Matlab
- Peter Corke's Robotics, Vision and Control toolbox
- CoppeliaSim simulator (earlier known as V-REP)
- Matlab bindings for CoppeliaSim

## Overview

The mobile robot used in these projects is a ```KUKA youBot```. It is controlled in a simulated environment (in CoppeliaSim) with bindings to communicate with the control program written in MATLAB.

Inputs to the MATLAB callback function consist of the position and orientation of the robot and data from the LIDAR sensor. Outputs from the program controls the linear and angular velocities of the simulated robot base wheels to perform a specified task. A Finite State Machine (FSM) manages the sequence of robot behaviours, e.g. initial, moving forward, stopping, moving backward. 

Topics covered in this repository : 
- Trajectory generations
- Wall following algorithm
- Bug2 algorithm
- Localisation using particle filter
- Wavefront planner

## Project 1

Introduces trajectory generation and basic control of the simulated Youbot using translational and rotational velocities.

![pic1](https://github.com/d-misra/Motion-planning-for-mobile-robots/blob/master/images/demo1.png)

- Straight-line trajectory generation
- Moving along a circular trajectory with constant orientation

The robot motion is generated by using proportional regulators with limited output.

Demos can be viewed [here](https://www.youtube.com/watch?v=2hio_rtz3Eo) and [here](https://www.youtube.com/watch?v=rdUNudgV34g). Code in ```code/solution1a.m``` and ```code/solution1b.m```

## Project 2

Introduces reactive control and navigation for obstacle avoidance using data gathered by LIDAR sensors. 

![pic1](https://github.com/d-misra/Motion-planning-for-mobile-robots/blob/master/images/demo2.png)

### Wall-following algorithm

The youBot moves along the wall, using LIDAR data to detect the wall and avoid collisions. The LIDAR sensor in the simulator has a range of 5 m and sends 684 rays, and is analysed to find the nearest obstacle. 3 proportional regulators are used to keep at a fixed distance to the wall, move along it and maintain perpendicular orientation. Code in ```code/solution2a.m```

[![pic1a](https://github.com/d-misra/Motion-planning-for-mobile-robots/blob/master/images/vid2a.png)](https://www.youtube.com/watch?v=587Ly53RAOk)

### Bug2 algorithm

Bug algorithms assume only local knowledge of the environment, and the robot has simple behaviours - move along a wall or along a straight line toward the goal. 

In Bug 2 algorithm, first a line joining the initial and goal positions, called the ```m-line``` is created. The robot starts to move along this line towards the goal. If an obstacle is encountered, the robot circumnavigates it until the m-line is encountered again, *closer to the goal*. Now the obstacle is left and the robot continues moving along the m-line to reach the goal. 

[![pic1b](https://github.com/d-misra/Motion-planning-for-mobile-robots/blob/master/images/vid2b.png)](https://www.youtube.com/watch?v=0qlQZZPEeEU)

More on Bug algorithms can be read [here](https://www.cs.cmu.edu/~motionplanning/lecture/Chap2-Bug-Alg_howie.pdf)

## Acknowledgments

Details of the project descriptions can be found on the official course [page](http://rcprg-ros-pkg.github.io/emor_trs/index.html).

Sometimes the official webpage is not available (or reads **yet to be announced**, depending when in the academic year since EMOR is taught in the winter semester). In such cases, please right click and copy the link address of the project html files (within the folder ```course_page```) and paste it in http://htmlpreview.github.io/
)
