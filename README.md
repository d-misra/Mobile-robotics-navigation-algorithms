# Robot navigation algorithms

A collection of algorithms for control and navigation of mobile robots. These programs were developed during my masters program's EMOR course tutorials (2016-17 session) at Warsaw University of Technology, Poland. Detailed project descriptions can be found on the official course [page](http://rcprg-ros-pkg.github.io/emor_trs/index.html). Setup instructions along with scenes and helper functions are provided, necessary to setup the environment used for these projects.

## Requirements
- Matlab
- Peter Corke's Robotics, Vision and Control toolbox
- [CoppeliaSim simulator](https://www.coppeliarobotics.com/) (earlier known as V-REP)
- Matlab bindings for CoppeliaSim

## Overview

The mobile robot used in these projects is a ```KUKA youBot```. It is controlled in a simulated environment (in CoppeliaSim) with bindings to communicate with the control program written in MATLAB.

Inputs to the MATLAB callback function consist of the robot's position and orientation and data from the LIDAR sensors. Outputs from the program controls the linear and angular velocities of the simulated robot base wheels to perform a specified task. A Finite State Machine (FSM) manages the sequence of robot behaviours, e.g. initial, moving forward, stopping, moving backward.

Topics covered in this repository :
- Trajectory generations
- Wall following algorithm
- Bug2 algorithm
- Localisation using particle filter
- Wavefront planner

## Project 1

Introduces trajectory generation and basic control of the simulated Youbot using translational and rotational velocities.

![pic1](https://github.com/d-misra/Motion-planning-for-mobile-robots/blob/master/images/demo1.png)

- Straight-line trajectory generation
- Moving along a circular trajectory with constant orientation

The robot motion is generated by using proportional regulators with limited output.

Demos can be viewed [here](https://www.youtube.com/watch?v=2hio_rtz3Eo) and [here](https://www.youtube.com/watch?v=rdUNudgV34g).
<!-- Code in ```code/solution1a.m``` and ```code/solution1b.m``` -->

## Project 2

Introduces reactive control and navigation for obstacle avoidance using data gathered by LIDAR sensors. The LIDAR sensor in the simulator has a range of 5 m and sends 684 rays, and is analysed to find the nearest obstacle.

![pic1](https://github.com/d-misra/Motion-planning-for-mobile-robots/blob/master/images/demo2.png)

### Wall-following algorithm

The youBot moves along the wall, using LIDAR data to detect the wall and avoid collisions. 3 proportional regulators are used to keep at a fixed distance to the wall, move along it and maintain perpendicular orientation.

<!-- Code in ```code/solution2a.m``` -->

[![pic1a](https://github.com/d-misra/Motion-planning-for-mobile-robots/blob/master/images/vid2a.png)](https://www.youtube.com/watch?v=587Ly53RAOk)

###  Bug2 algorithm

Bug algorithms assume only local knowledge of the environment, and the robot has simple behaviours - move along a wall or along a straight line toward the goal.

In Bug 2 algorithm, first a line joining the initial and goal positions, called the ```m-line``` is created. The robot starts to move along this line towards the goal. If an obstacle is encountered, the robot circumnavigates it until the m-line is encountered again, *closer to the goal*. Now the obstacle is left and the robot continues moving along the ```m-line``` to reach the goal.

<!-- Code in ```code/solution2b.m```. -->

[![pic1b](https://github.com/d-misra/Motion-planning-for-mobile-robots/blob/master/images/vid2b.png)](https://www.youtube.com/watch?v=0qlQZZPEeEU)

More on Bug algorithms can be read [here](https://www.cs.cmu.edu/~motionplanning/lecture/Chap2-Bug-Alg_howie.pdf)

## Project 3

Introduces localization and path planning algorithms.

###  Localisation using Particle Filter

In this task, the robot does not know its pose. Instead, the [odometry](https://groups.csail.mit.edu/drl/courses/cs54-2001s/odometry.html) for every control step is known. The robot's pose is estimated from odometry data and a provided map. Distance to the walls are computed using laser range sensors.

Here, we use a probabilistic state estimation technique using sampling-based distribution representation of a particle filter. Such localization is also known as Monte Carlo localization and the [wikipedia page](https://en.wikipedia.org/wiki/Monte_Carlo_localization) describes it as :


> The algorithm uses a particle filter to represent the distribution of likely states, with each particle representing a possible state, i.e., a hypothesis of where the robot is.[4] The algorithm typically starts with a uniform random distribution of particles over the configuration space, meaning the robot has no information about where it is and assumes it is equally likely to be at any point in space.[4] Whenever the robot moves, it shifts the particles to predict its new state after the movement. Whenever the robot senses something, the particles are resampled based on recursive Bayesian estimation, i.e., how well the actual sensed data correlate with the predicted state. Ultimately, the particles should converge towards the actual position of the robot.

<!-- Code in ```code/solution3a.m``` presents particle filter localization.  -->


[![pic1b](https://github.com/d-misra/Motion-planning-for-mobile-robots/blob/master/images/vid3a.png)](https://www.youtube.com/watch?v=72t36ocyBEg)

Some resources on Particle filter localization:
- A video [tutorial](https://www.youtube.com/watch?v=6bcktUxmOqQ) from Penn Engineering
- Original [publication](https://www.ri.cmu.edu/pub_files/pub1/dellaert_frank_1999_2/dellaert_frank_1999_2.pdf) on Monte Carlo localization for mobile robots
- A blog [post](https://towardsdatascience.com/particle-filter-on-localisation-9e0802282aaf) on particle filter localisation

### Path planning with Wavefront

Motion planning algorithm that prepares the robot trajectory off-line, i.e using the initial and goal positions only, through a discretized workspace. To create a "wave" of values, the destination is given the minimum cost, and the neighbouring cells are assigned progressively higher cost. An example of a wave of cost values is seen below (taken from [here](https://www.cs.cmu.edu/~16311/s07/labs/lab05/) where the obstacle has value 1 with goal and start points are labelled as 2 and 18.

![wave](https://github.com/d-misra/Motion-planning-for-mobile-robots/blob/master/images/wave.png)

A path is computed starting from the initial cell to the destination, by selecting the neighbouring cell with the smallest cost. The environment map is already known, where the obstacles (given a fixed cost value) are avoided for a collision-less trajectory. Multiple solutions can be found to reach the goal, and any path consisting of descending values of cost are acceptable. The demo below uses movement in only 4 directions (no diagonal movement).

[![pic1b](https://github.com/d-misra/Motion-planning-for-mobile-robots/blob/master/images/vid3c.png)](https://www.youtube.com/watch?v=y8L_n212hMY)

Other resources on wavefront planner :
-Tutorials [here](http://www.societyofrobots.com/programming_wavefront.shtml) and [here](https://www.cs.cmu.edu/~16311/s07/labs/lab05/)
- Wikipedia [article](https://www.cs.cmu.edu/~16311/s07/labs/lab05/)

## Additional information

Sometimes the official webpage is not available (or reads **yet to be announced**, depending when in the academic year since EMOR is taught in the winter semester). In such cases, please right click and copy the link address of the project html files (within the folder ```course_page```) and paste it in http://htmlpreview.github.io/
)

Since these tutorials are still part of the ongoing robotics curriculum evaluations at WUT, Poland, the Matlab code for these projects are not publicly released in this repository. It can be made available upon request.

## Acknowledgments

Many thanks to Prof. Dawid Seredy≈Ñski for conducting and preparing content for this excellent course, and also to my classmates and Shreyas for all the discussions and help.
