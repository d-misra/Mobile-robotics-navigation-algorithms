<!DOCTYPE html>

<html>
<head>
  <meta content="text/html; charset=utf-8" http-equiv="content-type">
  <link href="favicon.ico" rel="shortcut icon">

  <title>Mobile Robots (EMOR) tutorials</title>
  <link href="style.css" rel="stylesheet">
  <script type="text/javascript" src="http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>
</head>

<body>
  <div class="page">

    <div class="heading_body">
      <div style="text-align:left; font-size:160%;">
        <strong>Mobile Robots (EMOR)</strong> tutorials.
      </div>
    </div>

    <div class="content_body">

      <div id="menu">
        <a class="top" href="index.html">Introduction</a>
        <a href="setup.html">Setup</a>
        <a href="example.html">Example project</a>
        <a href="project1.html">Project 1</a>
        <a href="project2.html">Project 2</a>

          <a class="submenu" href="project2.html#description">Description</a>
          <a class="submenu" href="project2.html#wall">Moving along the walls</a>
          <a class="submenu" href="project2.html#bug2">Navigation with Bug2</a>

        <a href="project3.html">Project 3</a>
        <a href="api.html">API Documentation</a>
        <a href="tips.html">Tips & Tricks</a>
        <a href="troubleshooting.html">Troubleshooting</a>
      </div>

      <div class="content">
        <p>To be announced.</p>

        <a id="info" name="info"></a>
        <a id="description" name="description"></a>
        <h1 style="margin-top: 0">Description</h1>

          <p>The goal of the second EMOR tutorial is to introduce reactive control and navigation.
          The reactive control of the youBot robot is realized by using data acquired from the LIDAR sensor to avoid obstacles in a specified task (moving along the walls).
          In this tutorial the 'reactive control' refers to the control of the speed of the robot without any trajectory planning.
          The navigation is realized using the Bug2 algorithm.</p>

        <a id="wall" name="wall"></a>
        <h1 style="margin-top: 0">Moving along the walls</h1>

          <p>The goal of this subtask is to write a program enabling youBot to move along walls, as presented in the figure below.
          The robot should use laser scanners in order to detect the wall, move along it (i.e. keep the distance) and avoid collisions.</p>
          <div class="figure" style="width: 580px"><div><img style="border: 1px solid black; width: 560px" src="raster/tut_02_path.jpg" alt="tut2" /></div></div>

          <p>The video below shows an example motion generated by the controller you need to implement:</p>
          <iframe width="560" height="315" src="https://www.youtube.com/embed/BgH8s60vglg" frameborder="0" allowfullscreen></iframe>

          <p>Similarly to the previous tutorial, you should write a control function <code>solution2a</code> that implements proportional regulators that controls the robot movement.</p>

          <p>And analogically, we also prepared a simulation environment in V-REP stored in file <code>exercise02.ttt</code>.
          You must open it in V-REP before running your matlab script.</p>

          <h2>Programming hints</h2>

            <p>Similarly, as in the previous project, the motion of the robot should be controlled by variables representing the relative velocities:
            <ol>
              <li><code>forwBackVel</code> - linear velocity along the x axis of the robot,</li>
              <li><code>leftRightVel</code> - linear velocity along the y axis of the robot,</li>
              <li><code>rotVel</code> - angular velocity around the z axis of the robot.</li>
            </ol>
            </p>

            <p>Additionally, you should gather and analyse data from the lidar sensors (the laser range sensors).
            There are two variables that keep the LIDAR data:
            <ol>
              <li><code>pts</code> - a table containing LIDAR readings: the end-of-ray points, i.e. contact points of rays and obstacles in sensors's coordinates, each expressed as [x;y;z],</li>
              <li><code>contacts</code> - a table of values <0/1> determining whether an obstactle was detected or the reading corresponds to the maximal sensor range (in this case it is set to 5m).</li>
            </ol>
            The input variables that describe the pose of the robot: <code>position</code> and <code>orientation</code> are not relevant in this tutorial.
            The input data from the LIDAR sensor is sufficient to control the movements of the robot in a desired way.</p>

            <p>To better understand the data acquired from LIDAR sensor, consider a simple example:
            <div class="figure" style="width: 580px"><div><img style="border: 1px solid black; width: 560px" src="raster/lidar_small.jpg" alt="lidar_small" /></div></div>
            In this example the LIRAR sends only three rays and one of them hits an obstacle. The array <code>pts</code> contains end-of-ray points
            (the contact points of rays with obstacles), and in this particular case it is
<code class="block">-1.6  0.0   1.6
-1.6  -0.5   -1.6
0.08  0.08  0.08</code>
            where each column represents x, y and z coordinates of the contact point of the laser ray and an obstacle.
            If a laser ray is not hitting an obstacle, its contact point is at the end of the ray within a specified range (in the example, the LIDAR range is set to 2 m, so the rays end 2 meters from the sensor).
            The <code>contacts</code> array contains values indicating if rays hit obstacles. In the example, the array is:
            <code class="block">0 1 0</code>
            The central ray hits an obstacle, so its corresponding value in the <code>contacts</code> array is 1. Also, its contact point in the <code>pts</code> table is [0, 0.5, 0.08].
            As the other two rays are not in contact with obstacles, their corresponding values in the <code>contacts</code> array are 0 and their corresponding end-of-ray points in the
            <code>pts</code> table are at distance of 2 m from the sensor (the maximal range of the sensor in this example).</p>

            <p>Please note that the LIDAR sensor used in the simulator has range of 5 m and sends 684 rays, so the lengths of <code>pts</code> table and <code>contacts</code> array are 684.</p>
            <div class="figure" style="width: 580px"><div><img style="border: 1px solid black; width: 560px" src="raster/lidar.jpg" alt="lidar_small" /></div></div>

          <h2>Task requirements</h2>
            <ol>
              <li>Analyse the lidar readings in order to find the nearest obstacle (please consider the XY plane readings only). </li>
              <li>The robot should keep given distance to the wall (e.g. 1 m), hence you must compute the relative errors in directions perpendicular and parallel to the wall. </li>
              <li>The resulting robot speed should be computed on the basis of those errors. </li>
              <li>Additionally, the robot must always face the wall, hence you must also adequtelly control the angular robot velocity. </li>
              <li>Do not use the input variables <code>position</code> and <code>orientation</code>, as they are not relevant.</li>
            </ol>


          <h2 style="margin-top: 0">Grading (4 points total)</h2>
            <ol>
              <li>Processing of the sensory data (1p)</li>
              <li>Regulator keeping distance from the wall (1p)</li>
              <li>Regulator responsible for moving the robot along the wall (1p)</li>
              <li>Regulator keeping the perpendicular orientation of the robot againts the wall (1p)</li>
            </ol>


        <a id="bug2" name="bug2"></a>
        <h1>Navigation with Bug2</h2>

          <p>Write a program implementing the Bug2 algorithm. The basic idea is to move along the line connecting the target and initial point and
          in the case of being near to the obstacle follow its contour and thus circumnavigate it.
          The program should work as follows:
          <ol>
            <li>Find the line <code>l</code> connecting initial and target position.</li>
            <li>Rotate towards the goal.</li>
            <li>Move towards the goal along the <code>l</code> line until reaching an obstacle or the goal.</li>
            <li>When the robot reaches the obstacle, save the distance to the goal <code>d</code>.</li>
            <li>Use "moving along the walls" controller to avoid the obstacle.</li>
            <li>Depart immediately when the robot is on the <code>l</code> line again and the distance to the goal is lower than <code>d</code>.</li>
            <li>Go to the step 2.</li>
          </ol>
          </p>

          <h2>Programming hints</h2>
            <p>Implement a control callback function <code>solution2b</code> that realizes the Bug2 navigation task.
            Use the input variables <code>position</code> and <code>orientation</code> to determine the line <code>l</code> and to calculate the distance <code>d</code>.
            The goal point should be provided as an additional input argument to the function <code>solution2b</code>, so running the simualtion would be:
<code class="block">run_simulation(@solution2b, false, [goal_x, goal_y])</code>
            </p>
            <p>You can refer to a implementation of the Bug2 algorithm in the Robotics Toolbox. Please see the file <code>~/ws_emor/emor_trs/matlab/rvctools/robot/Bug2.m</code>.</p>

          <h2>Task requirements</h2>
            <ol>
              <li>Analyse the LIDAR readings to check if the robot is close to obstacle.</li>
              <li>Use the Finite State Machine (FSM) for switching between different states of Bug2 algorithm (e.g. heading towards the goal, moving along the walls).</li>
              <li>Use the "moving along the walls" controller to circumnavigate the obstacles.</li>
              <li>Use proportional controllers with limited output to move the robot along the line <code>l</code>.</li>
              <li>The line <code>l</code> should be calculated once, in the initial state.</li>
              <li>If the robot reaches the goal, stop the controller.</li>
            </ol>

          <h2 style="margin-top: 0">Grading (4 points total)</h2>
            <ol>
              <li>Processing of the sensory data (1p)</li>
              <li>Overall Bug2 implementation quality, Finite State Machine (1p)</li>
              <li>Regulators that keep the robot on the line <code>l</code> (1p)</li>
              <li>Stop condition and clean exit (1p)</li>
            </ol>

    </div>

      <div class="trailer_body">
        <div style="width: 100%; display: table;">
          <div style="display: table-row">
            <div style="width: 50%; display: table-cell; vertical-align: bottom;">
              Valid <a href="http://validator.w3.org/check?uri=referer">HTML5</a> and <a href="http://jigsaw.w3.org/css-validator/check/referer">CSS</a>
            </div>

            <div style="width: 50%; display: table-cell; text-align: right; vertical-align: bottom;">
              &copy; Renaud Detry 2014<br>
              &copy; Dawid Seredyński, Tomasz Kornuta 2016<br>
              This work is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International License</a>.
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</body>
</html>
